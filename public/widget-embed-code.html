<!-- AI Agent Widget - Copy and paste this entire code block into your website -->
<div id="ai-agent-widget">
<style>
/* AI Agent Widget Styles */
.ai-widget-container{position:fixed;bottom:20px;right:20px;z-index:9999;font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,sans-serif}.ai-widget-button{width:60px;height:60px;border-radius:50%;background:linear-gradient(135deg,#d97706,#f59e0b);border:none;box-shadow:0 4px 20px rgba(0,0,0,0.15);cursor:pointer;transition:all 0.3s ease;display:flex;align-items:center;justify-content:center;color:white;font-size:24px}.ai-widget-button:hover{transform:scale(1.1);box-shadow:0 6px 25px rgba(0,0,0,0.2)}.ai-widget-modal{position:fixed;top:0;left:0;width:100%;height:100%;background:rgba(0,0,0,0.6);backdrop-filter:blur(4px);display:flex;align-items:center;justify-content:center;z-index:10000}.ai-widget-modal.hidden{display:none}.ai-widget-content{background:white;border:1px solid #e5e7eb;border-radius:16px;box-shadow:0 20px 25px -5px rgba(0,0,0,0.1);padding:32px;max-width:400px;width:90%;text-align:center}.ai-widget-title{font-size:24px;font-weight:bold;color:#d97706;margin-bottom:16px}.ai-widget-canvas{width:300px;height:100px;background:linear-gradient(135deg,#fef7ed,#fed7aa);border:1px solid #fed7aa;border-radius:8px;margin:0 auto 16px;display:block}.ai-widget-button-primary{background:#d97706;color:white;font-weight:600;padding:8px 24px;border-radius:9999px;border:none;cursor:pointer;transition:all 0.3s ease;box-shadow:0 2px 4px rgba(0,0,0,0.1)}.ai-widget-button-primary:hover{background:#b45309}.ai-widget-button-primary:disabled{background:#d1d5db;color:#6b7280;cursor:not-allowed}.ai-widget-status{font-size:12px;color:#6b7280;margin-top:12px}.ai-widget-close{margin-top:16px;font-size:14px;color:#d97706;text-decoration:underline;background:none;border:none;cursor:pointer}.ai-widget-close:hover{color:#b45309}
</style>

<div class="ai-widget-container">
    <button class="ai-widget-button" onclick="AIWidget.open()">🤖</button>
    <div id="ai-widget-modal" class="ai-widget-modal hidden">
        <div class="ai-widget-content">
            <h3 class="ai-widget-title" id="ai-widget-title">Talk to Your AI Agent</h3>
            <canvas id="ai-widget-canvas" class="ai-widget-canvas" width="300" height="100"></canvas>
            <button id="ai-widget-talk-btn" class="ai-widget-button-primary" onclick="AIWidget.toggleRecording()">Start Talking</button>
            <p class="ai-widget-status">You're chatting live with Agent</p>
            <button class="ai-widget-close" onclick="AIWidget.close()">Close</button>
        </div>
    </div>
</div>

<script>
window.AIWidget = (function() {
    // CONFIGURATION - Replace with your agent ID
    const AGENT_ID = 'YOUR_AGENT_ID_HERE'; // ⚠️ REPLACE THIS WITH YOUR ACTUAL AGENT ID
    
    let isRecording = false;
    let audioContext = null;
    let analyser = null;
    let dataArray = null;
    let source = null;
    let animationFrame = null;
    let processor = null;
    let audioQueue = [];
    let isPlaying = false;
    let currentSource = null;
    let socket = null;

    function open() {
        if (!AGENT_ID || AGENT_ID === 'YOUR_AGENT_ID_HERE') {
            alert('Please configure your agent ID in the widget code');
            return;
        }
        document.getElementById('ai-widget-modal').classList.remove('hidden');
    }

    function close() {
        document.getElementById('ai-widget-modal').classList.add('hidden');
        if (isRecording) stop();
    }

    function toggleRecording() {
        isRecording ? stop() : start();
    }

    async function start() {
        if (!AGENT_ID || AGENT_ID === 'YOUR_AGENT_ID_HERE') {
            alert('Agent ID not configured');
            return;
        }

        isRecording = true;
        document.getElementById('ai-widget-title').textContent = 'Talking to Agent...';
        document.getElementById('ai-widget-talk-btn').textContent = 'Stop';

        try {
            await startAudio();
            startWebSocket();
        } catch (error) {
            console.error('Error starting recording:', error);
            alert('Could not access microphone. Please check permissions.');
            stop();
        }
    }

    function stop() {
        isRecording = false;
        document.getElementById('ai-widget-title').textContent = 'Talk to Your AI Agent';
        document.getElementById('ai-widget-talk-btn').textContent = 'Start Talking';
        stopAudio();
        stopWebSocket();
    }

    async function startAudio() {
        audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        source = audioContext.createMediaStreamSource(stream);
        analyser = audioContext.createAnalyser();
        source.connect(analyser);
        analyser.fftSize = 256;
        dataArray = new Uint8Array(analyser.frequencyBinCount);

        const canvas = document.getElementById('ai-widget-canvas');
        const ctx = canvas.getContext('2d');

        function draw() {
            if (!isRecording) return;
            animationFrame = setTimeout(() => requestAnimationFrame(draw), 60);
            analyser.getByteTimeDomainData(dataArray);
            ctx.clearRect(0, 0, canvas.width, canvas.height);

            const width = canvas.width, height = canvas.height, middle = height / 2;
            const sliceWidth = width / dataArray.length;
            let x = 0, maxAmplitude = 0;

            ctx.beginPath();
            for (let i = 0; i < dataArray.length; i++) {
                const v = dataArray[i] / 128.0;
                const y = middle + (v - 1.0) * middle * 0.75;
                if (Math.abs(v - 1.0) > maxAmplitude) maxAmplitude = Math.abs(v - 1.0);
                i === 0 ? ctx.moveTo(x, y) : ctx.lineTo(x, y);
                x += sliceWidth;
            }

            const gradient = ctx.createLinearGradient(0, 0, canvas.width, 0);
            gradient.addColorStop(0, '#d97706');
            gradient.addColorStop(0.5, '#f59e0b');
            gradient.addColorStop(1, '#fbbf24');
            ctx.strokeStyle = gradient;
            ctx.lineWidth = 4;
            ctx.lineJoin = 'round';
            ctx.lineCap = 'round';
            ctx.stroke();

            if (maxAmplitude > 0.15 && isPlaying) {
                audioQueue = [];
                if (currentSource) {
                    currentSource.stop();
                    currentSource.disconnect();
                    currentSource = null;
                }
                isPlaying = false;
            }
        }
        draw();

        processor = audioContext.createScriptProcessor(4096, 1, 1);
        source.connect(processor);
        processor.connect(audioContext.destination);
        processor.onaudioprocess = (e) => {
            const input = e.inputBuffer.getChannelData(0);
            const pcm = new Int16Array(input.length);
            for (let i = 0; i < input.length; i++) {
                pcm[i] = Math.max(-1, Math.min(1, input[i])) * 0x7fff;
            }
            const base64 = btoa(String.fromCharCode(...new Uint8Array(pcm.buffer)));
            if (socket?.readyState === WebSocket.OPEN) {
                socket.send(JSON.stringify({ user_audio_chunk: base64 }));
            }
        };
    }

    function stopAudio() {
        if (animationFrame) cancelAnimationFrame(animationFrame);
        if (processor) processor.disconnect();
        if (audioContext) audioContext.close();
    }

    function startWebSocket() {
        socket = new WebSocket(`wss://api.elevenlabs.io/v1/convai/conversation?agent_id=${AGENT_ID}`);
        socket.onopen = () => socket.send(JSON.stringify({
            type: "conversation_initiation_client_data",
            conversation_config_override: { agent: { agent_id: AGENT_ID } }
        }));
        socket.onmessage = async (message) => {
            const data = JSON.parse(message.data);
            if (data.type === "audio" && data.audio_event?.audio_base_64) {
                try {
                    const raw = atob(data.audio_event.audio_base_64);
                    const buffer = new ArrayBuffer(raw.length);
                    const view = new Uint8Array(buffer);
                    for (let i = 0; i < raw.length; i++) view[i] = raw.charCodeAt(i);
                    const dataView = new DataView(buffer);
                    const pcm = new Float32Array(buffer.byteLength / 2);
                    for (let i = 0; i < pcm.length; i++) {
                        pcm[i] = dataView.getInt16(i * 2, true) / 32768;
                    }
                    const audioBuffer = audioContext.createBuffer(1, pcm.length, 16000);
                    audioBuffer.copyToChannel(pcm, 0);
                    audioQueue.push(audioBuffer);
                    playNext();
                } catch (err) {
                    console.error('Audio decode error:', err);
                }
            }
        };
    }

    function stopWebSocket() {
        if (socket) socket.close();
    }

    function playNext() {
        if (isPlaying || !audioQueue.length) return;
        const buffer = audioQueue.shift();
        currentSource = audioContext.createBufferSource();
        currentSource.buffer = buffer;
        currentSource.connect(audioContext.destination);
        isPlaying = true;
        currentSource.onended = () => {
            isPlaying = false;
            currentSource = null;
            playNext();
        };
        currentSource.start();
    }

    // Close on outside click
    document.addEventListener('click', (e) => {
        if (e.target.id === 'ai-widget-modal') close();
    });

    return { open, close, toggleRecording };
})();
</script>
</div>

<!-- 
INSTRUCTIONS FOR USE:
1. Replace 'YOUR_AGENT_ID_HERE' with your actual agent ID (line 13)
2. Copy this entire code block and paste it anywhere in your HTML body
3. The widget will appear as a floating button in the bottom-right corner
4. Users can click the button to start talking to your AI agent

FEATURES:
- Floating chat button
- Real-time voice conversation with AI agent
- Visual waveform during recording
- Automatic interruption handling
- Mobile-responsive design
- No external dependencies
-->